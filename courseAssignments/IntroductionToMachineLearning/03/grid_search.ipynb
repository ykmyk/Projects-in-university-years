{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77dc272e-de11-4bc0-a485-577bcbeed3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import argparse\n",
    "\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "import sklearn.pipeline\n",
    "import sklearn.preprocessing\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "# These arguments will be set appropriately by ReCodEx, even if you change them.\n",
    "parser.add_argument(\"--recodex\", default=False, action=\"store_true\", help=\"Running in ReCodEx\")\n",
    "parser.add_argument(\"--seed\", default=42, type=int, help=\"Random seed\")\n",
    "parser.add_argument(\"--test_size\", default=0.5, type=lambda x: int(x) if x.isdigit() else float(x), help=\"Test size\")\n",
    "# If you add more arguments, ReCodEx will keep them with your default values.\n",
    "args = parser.parse_args([] if \"__file__\" not in globals() else None)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90ea8e3a-f0d9-475d-bcb7-24c06f0aea54",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Load the digits dataset.\n",
    "    dataset = sklearn.datasets.load_digits()\n",
    "    dataset.target = dataset.target % 2\n",
    "    d = dataset.data \n",
    "    \n",
    "    # If you want to learn about the dataset, you can print some information\n",
    "    # about it using `print(dataset.DESCR)`.\n",
    "    \n",
    "    # TODO: Split the dataset into a train set and a test set.\n",
    "    # Use `sklearn.model_selection.train_test_split` method call, passing\n",
    "    # arguments `test_size=args.test_size, random_state=args.seed`.\n",
    "    train_data, test_data, train_target, test_target = sklearn.model_selection.train_test_split(\n",
    "        d, dataset.target, test_size=args.test_size, random_state=args.seed\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ad7b3ec-dc6f-4a2a-8560-f070b62f925f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukamiyake/2025ws/ML/tut/lab_venv/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yukamiyake/2025ws/ML/tut/lab_venv/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yukamiyake/2025ws/ML/tut/lab_venv/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yukamiyake/2025ws/ML/tut/lab_venv/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yukamiyake/2025ws/ML/tut/lab_venv/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yukamiyake/2025ws/ML/tut/lab_venv/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yukamiyake/2025ws/ML/tut/lab_venv/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yukamiyake/2025ws/ML/tut/lab_venv/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yukamiyake/2025ws/ML/tut/lab_venv/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yukamiyake/2025ws/ML/tut/lab_venv/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yukamiyake/2025ws/ML/tut/lab_venv/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yukamiyake/2025ws/ML/tut/lab_venv/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yukamiyake/2025ws/ML/tut/lab_venv/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yukamiyake/2025ws/ML/tut/lab_venv/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yukamiyake/2025ws/ML/tut/lab_venv/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9799777530589544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukamiyake/2025ws/ML/tut/lab_venv/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# TODO: Create a pipeline, which\n",
    "# 1. passes the inputs through `sklearn.preprocessing.MinMaxScaler()`,\n",
    "# 2. passes the result through `sklearn.preprocessing.PolynomialFeatures()`,\n",
    "# 3. passes the result through `sklearn.linear_model.LogisticRegression(random_state=args.seed)`.\n",
    "\n",
    "pipe = sklearn.pipeline.Pipeline([\n",
    "    (\"scaler\", sklearn.preprocessing.MinMaxScaler()),\n",
    "    (\"poly\", sklearn.preprocessing.PolynomialFeatures()),\n",
    "    (\"logireg\", sklearn.linear_model.LogisticRegression(random_state=args.seed))\n",
    "     ])\n",
    "\n",
    "# pipe.fit(train_data, train_target)\n",
    "\n",
    "# Then, using `sklearn.model_selection.StratifiedKFold` with 5 folds, evaluate\n",
    "# crossvalidated train performance of all combinations of the following parameters:\n",
    "# - polynomial degree: 1, 2\n",
    "# - LogisticRegression regularization C: 0.01, 1, 100\n",
    "# - LogisticRegression solver: lbfgs, sag\n",
    "# Keep the other parameters at their default values.\n",
    "\n",
    "skf = sklearn.model_selection.StratifiedKFold(n_splits=5)\n",
    "\n",
    "params = {\n",
    "    'poly__degree':[1, 2],\n",
    "    'logireg__C':[0.01, 1, 10],\n",
    "    'logireg__solver':('lbfgs', 'sag')\n",
    "}\n",
    "\n",
    "# For the best combination of parameters, compute the test set accuracy.\n",
    "# The easiest way is to use `sklearn.model_selection.GridSearchCV`.\n",
    "\n",
    "model = sklearn.model_selection.GridSearchCV(estimator=pipe, param_grid=params, cv=skf)\n",
    "model.fit(train_data, train_target)\n",
    "\n",
    "test_accuracy = model.score(test_data, test_target)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.ConvergenceWarning)\n",
    "# If `model` is a fitted `GridSearchCV`, you can use the following code\n",
    "# to show the results of all the hyperparameter values evaluated:\n",
    "#   for rank, accuracy, params in zip(model.cv_results_[\"rank_test_score\"],\n",
    "#                                     model.cv_results_[\"mean_test_score\"],\n",
    "#                                     model.cv_results_[\"params\"]):\n",
    "#       print(\"Rank: {:2d} Cross-val: {:.1f}%\".format(rank, 100 * accuracy),\n",
    "#             *(\"{}: {:<5}\".format(key, value) for key, value in params.items()))\n",
    "\n",
    "# Note that with some hyperparameter values above, the training does not\n",
    "# converge in the default limit of 100 epochs and shows `ConvergenceWarning`s.\n",
    "# You can verify that increasing the number of epochs influences the results\n",
    "# only marginally, so there is no reason to do it. To get rid of the warnings,\n",
    "# you can add `-W ignore::UserWarning` just after `python` on the command line,\n",
    "# or you can use the following code (and the corresponding imports):\n",
    "#   warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.ConvergenceWarning)\n",
    "\n",
    "return 100 * test_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eef9b2f-5a2b-47cb-a43c-c20ceeef56f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
