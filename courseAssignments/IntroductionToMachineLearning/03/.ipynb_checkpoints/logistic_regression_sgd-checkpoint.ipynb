{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bf14b4b-cae7-4dae-96af-c70f9ab7a2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import argparse\n",
    "import math\n",
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "# These arguments will be set appropriately by ReCodEx, even if you change them.\n",
    "parser.add_argument(\"--batch_size\", default=10, type=int, help=\"Batch size\")\n",
    "parser.add_argument(\"--data_size\", default=100, type=int, help=\"Data size\")\n",
    "parser.add_argument(\"--epochs\", default=50, type=int, help=\"Number of SGD training epochs\")\n",
    "parser.add_argument(\"--learning_rate\", default=0.01, type=float, help=\"Learning rate\")\n",
    "parser.add_argument(\"--plot\", default=False, const=True, nargs=\"?\", type=str, help=\"Plot the predictions\")\n",
    "parser.add_argument(\"--recodex\", default=False, action=\"store_true\", help=\"Running in ReCodEx\")\n",
    "parser.add_argument(\"--seed\", default=42, type=int, help=\"Random seed\")\n",
    "parser.add_argument(\"--test_size\", default=0.5, type=lambda x: int(x) if x.isdigit() else float(x), help=\"Test size\")\n",
    "# If you add more arguments, ReCodEx will keep them with your default values.\n",
    "args = parser.parse_args([] if \"__file__\" not in globals() else None)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2c5d73a-35ce-4224-95ef-55aa41b4ee51",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = np.random.RandomState(args.seed)\n",
    "\n",
    "# Generate an artificial classification dataset.\n",
    "data, target = sklearn.datasets.make_classification(\n",
    "    n_samples=args.data_size, n_features=2, n_informative=2, n_redundant=0, random_state=args.seed)\n",
    "\n",
    "# TODO: Append a constant feature with value 1 to the end of all input data.\n",
    "# Then we do not need to explicitly represent bias - it becomes the last weight.\n",
    "X = np.c_[data, np.ones(data.shape[0], dtype=int)]\n",
    "\n",
    "# TODO: Split the dataset into a train set and a test set.\n",
    "# Use `sklearn.model_selection.train_test_split` method call, passing\n",
    "# arguments `test_size=args.test_size, random_state=args.seed`\n",
    "train_data, test_data, train_target, test_target = sklearn.model_selection.train_test_split(\n",
    "    X, target, test_size=args.test_size, random_state=args.seed\n",
    ")\n",
    "\n",
    "# Generate initial logistic regression weights.\n",
    "weights = generator.uniform(size=train_data.shape[1], low=-0.1, high=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b6fd2a7-cbcf-44f6-a795-95b4c27a57df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20edab1d-fa2d-4878-b0ce-95099dc27334",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/77/pm8_tkpd5sj9jvfyrhdbgxqc0000gn/T/ipykernel_92098/237825215.py:40: RuntimeWarning: divide by zero encountered in log\n",
      "  test_loss = np.mean(- t_test * np.log(pred_test) - (1 - t_test) * np.log(1 - pred_test))\n",
      "/var/folders/77/pm8_tkpd5sj9jvfyrhdbgxqc0000gn/T/ipykernel_92098/237825215.py:40: RuntimeWarning: invalid value encountered in multiply\n",
      "  test_loss = np.mean(- t_test * np.log(pred_test) - (1 - t_test) * np.log(1 - pred_test))\n",
      "/var/folders/77/pm8_tkpd5sj9jvfyrhdbgxqc0000gn/T/ipykernel_92098/237825215.py:39: RuntimeWarning: divide by zero encountered in log\n",
      "  train_loss = np.mean(- t_train * np.log(pred_train) - (1 - t_train) * np.log(1 - pred_train))\n",
      "/var/folders/77/pm8_tkpd5sj9jvfyrhdbgxqc0000gn/T/ipykernel_92098/237825215.py:39: RuntimeWarning: invalid value encountered in multiply\n",
      "  train_loss = np.mean(- t_train * np.log(pred_train) - (1 - t_train) * np.log(1 - pred_train))\n",
      "/var/folders/77/pm8_tkpd5sj9jvfyrhdbgxqc0000gn/T/ipykernel_92098/3082863818.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(args.epochs):\n",
    "    permutation = generator.permutation(train_data.shape[0])\n",
    "\n",
    "    # TODO: Process the data in the order of `permutation`. For every\n",
    "    # `args.batch_size` of them, average their gradient, and update the weights.\n",
    "    # You can assume that `args.batch_size` exactly divides `train_data.shape[0]`.\n",
    "    b_size = args.batch_size\n",
    "    for i in range(0, train_data.shape[0], b_size):\n",
    "        indices= permutation[i : i + b_size]\n",
    "        X_batch = train_data[indices]\n",
    "        t_batch = train_target[indices]\n",
    "        gradient -= ((sigmod(X_batch @ weights) - t_batch) @ X_batch) / b_size\n",
    "        \n",
    "        weights -= args.learning_rate * gradient\n",
    "\n",
    "    pred_train = sigmoid(X_batch @ weights)\n",
    "    pred_test = sigmoid(test_data @ weights)\n",
    "\n",
    "    t_train = np.zeros(len(pred_train), dtype=int)\n",
    "    t_test = np.zeros(len(pred_test), dtype=int)\n",
    "\n",
    "    train_accuracy = 0\n",
    "    test_accuracy = 0\n",
    "    for i in range(len(pred_train)):\n",
    "        if pred_train[i] >= 0.5:\n",
    "            t_train[i] = 1\n",
    "            train_accuracy += 1\n",
    "        else:\n",
    "            t_train[i] = 0\n",
    "            \n",
    "    for i in range(len(pred_test)):\n",
    "        if pred_test[i] >= 0.5:\n",
    "            t_test[i] = 1\n",
    "            test_accuracy += 1\n",
    "        else:\n",
    "            t_test[i] = 0\n",
    "\n",
    "    # log(pred_train)^t_train = t_train * log(pred_train)\n",
    "    train_loss = np.mean(- t_train * np.log(pred_train) - (1 - t_train) * np.log(1 - pred_train))\n",
    "    test_loss = np.mean(- t_test * np.log(pred_test) - (1 - t_test) * np.log(1 - pred_test))\n",
    "    \n",
    "    train_accuracy /= b_size\n",
    "    test_accuracy /= b_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48e5864-0aa9-43a9-9fad-20ca837d5f79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
